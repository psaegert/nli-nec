{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psaegert/miniconda3/envs/fsem/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlinec import get_positive_data, get_all_types, get_results_dir, get_models_dir\n",
    "from nlinec.predict import predict_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset to predict and a file to save the predictions to\n",
    "DATASET = 'g_test.json'\n",
    "MODEL = \"nlinec-2-logging\"\n",
    "\n",
    "SAVE_MODEL_TO = os.path.join(get_models_dir(), MODEL)\n",
    "SAVE_PREDICTIONS_TO = os.path.join(get_results_dir(), \"predictions\", MODEL, \"test_predictions.csv\")\n",
    "\n",
    "# Specify the parameters for the prediction\n",
    "HYPOTHESIS_ONLY = True\n",
    "SAVE_EVERY = 100_000\n",
    "\n",
    "# Use the GPU if available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Make sure the directory to save the predictions to exists\n",
    "os.makedirs(os.path.dirname(SAVE_PREDICTIONS_TO), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(DEVICE)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(SAVE_MODEL_TO).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_type</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/location/country</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/location</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/other/scientific</td>\n",
       "      <td>scientific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>/location/geography/body_of_water</td>\n",
       "      <td>body_of_water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>/location/geograpy/island</td>\n",
       "      <td>island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/location/geograpy</td>\n",
       "      <td>geograpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>/other/legal</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/other/product/mobile_phone</td>\n",
       "      <td>mobile_phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            full_type           type\n",
       "0                              /other          other\n",
       "1                   /location/country        country\n",
       "2                           /location       location\n",
       "3                   /other/scientific     scientific\n",
       "4                      /location/city           city\n",
       "..                                ...            ...\n",
       "84  /location/geography/body_of_water  body_of_water\n",
       "85          /location/geograpy/island         island\n",
       "86                 /location/geograpy       geograpy\n",
       "87                       /other/legal          legal\n",
       "88        /other/product/mobile_phone   mobile_phone\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make entailment predictions for all types and filter out the relevant ones later in the analysis\n",
    "all_types = get_all_types(granularity=-1)\n",
    "all_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading g_test.json: 8963it [00:00, 85365.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention_span</th>\n",
       "      <th>full_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valley Federal Savings &amp; Loan Association</td>\n",
       "      <td>[/organization, /organization/company]</td>\n",
       "      <td>Valley Federal Savings &amp; Loan Association sai...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valley Federal</td>\n",
       "      <td>[/organization, /organization/company]</td>\n",
       "      <td>Terms weren't disclosed, but Valley Federal ha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valley Federal</td>\n",
       "      <td>[/organization, /organization/company]</td>\n",
       "      <td>Valley Federal said Friday that it is conside...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valley Federal , with assets of $ 3.3 billion ,</td>\n",
       "      <td>[/organization, /organization/company]</td>\n",
       "      <td>Valley Federal , with assets of $ 3.3 billion...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imperial Corp. of America</td>\n",
       "      <td>[/organization, /organization/company]</td>\n",
       "      <td>Valley Federal Savings &amp; Loan Association said...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>Fridays in general , which tend to be strong d...</td>\n",
       "      <td>[/other]</td>\n",
       "      <td>Another study found that the 82 Fridays the 13...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>stocks</td>\n",
       "      <td>[/other]</td>\n",
       "      <td>But the date tends to be a plus, not a minus, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>the 1962 - 85 period</td>\n",
       "      <td>[/other]</td>\n",
       "      <td>But their study, which spanned the 1962 - 85 p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>professors</td>\n",
       "      <td>[/person]</td>\n",
       "      <td>Robert Kolb and Ricardo Rodriguez, professors ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>Just a coincidence</td>\n",
       "      <td>[/other]</td>\n",
       "      <td>Just a coincidence ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8963 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mention_span  \\\n",
       "0             Valley Federal Savings & Loan Association   \n",
       "1                                        Valley Federal   \n",
       "2                                        Valley Federal   \n",
       "3       Valley Federal , with assets of $ 3.3 billion ,   \n",
       "4                             Imperial Corp. of America   \n",
       "...                                                 ...   \n",
       "8958  Fridays in general , which tend to be strong d...   \n",
       "8959                                             stocks   \n",
       "8960                               the 1962 - 85 period   \n",
       "8961                                         professors   \n",
       "8962                                 Just a coincidence   \n",
       "\n",
       "                                   full_type  \\\n",
       "0     [/organization, /organization/company]   \n",
       "1     [/organization, /organization/company]   \n",
       "2     [/organization, /organization/company]   \n",
       "3     [/organization, /organization/company]   \n",
       "4     [/organization, /organization/company]   \n",
       "...                                      ...   \n",
       "8958                                [/other]   \n",
       "8959                                [/other]   \n",
       "8960                                [/other]   \n",
       "8961                               [/person]   \n",
       "8962                                [/other]   \n",
       "\n",
       "                                               sentence  label  \n",
       "0      Valley Federal Savings & Loan Association sai...      2  \n",
       "1     Terms weren't disclosed, but Valley Federal ha...      2  \n",
       "2      Valley Federal said Friday that it is conside...      2  \n",
       "3      Valley Federal , with assets of $ 3.3 billion...      2  \n",
       "4     Valley Federal Savings & Loan Association said...      2  \n",
       "...                                                 ...    ...  \n",
       "8958  Another study found that the 82 Fridays the 13...      2  \n",
       "8959  But the date tends to be a plus, not a minus, ...      2  \n",
       "8960  But their study, which spanned the 1962 - 85 p...      2  \n",
       "8961  Robert Kolb and Ricardo Rodriguez, professors ...      2  \n",
       "8962                               Just a coincidence ?      2  \n",
       "\n",
       "[8963 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_positive_data(DATASET)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If some predictions already exist, load them\n",
    "if os.path.exists(SAVE_PREDICTIONS_TO):\n",
    "    # Load the predictions from file\n",
    "    print(\"Loading predictions from file\")\n",
    "    predictions_df = pd.read_csv(SAVE_PREDICTIONS_TO, index_col=0)\n",
    "else:\n",
    "    # Create a dataframe with the same index as the data\n",
    "    predictions_df = pd.DataFrame(columns=list(all_types['full_type']), index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>/other</th>\n",
       "      <th>/location/country</th>\n",
       "      <th>/location</th>\n",
       "      <th>/other/scientific</th>\n",
       "      <th>/location/city</th>\n",
       "      <th>/other/product</th>\n",
       "      <th>/other/event/sports_event</th>\n",
       "      <th>/other/event</th>\n",
       "      <th>/other/art</th>\n",
       "      <th>/other/art/broadcast</th>\n",
       "      <th>...</th>\n",
       "      <th>/organization/stock_exchange</th>\n",
       "      <th>/location/transit/bridge</th>\n",
       "      <th>/organization/company/broadcast</th>\n",
       "      <th>/organization/transit</th>\n",
       "      <th>/location/structure/theater</th>\n",
       "      <th>/location/geography/body_of_water</th>\n",
       "      <th>/location/geograpy/island</th>\n",
       "      <th>/location/geograpy</th>\n",
       "      <th>/other/legal</th>\n",
       "      <th>/other/product/mobile_phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8963 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     /other /location/country /location /other/scientific /location/city  \\\n",
       "0       NaN               NaN       NaN               NaN            NaN   \n",
       "1       NaN               NaN       NaN               NaN            NaN   \n",
       "2       NaN               NaN       NaN               NaN            NaN   \n",
       "3       NaN               NaN       NaN               NaN            NaN   \n",
       "4       NaN               NaN       NaN               NaN            NaN   \n",
       "...     ...               ...       ...               ...            ...   \n",
       "8958    NaN               NaN       NaN               NaN            NaN   \n",
       "8959    NaN               NaN       NaN               NaN            NaN   \n",
       "8960    NaN               NaN       NaN               NaN            NaN   \n",
       "8961    NaN               NaN       NaN               NaN            NaN   \n",
       "8962    NaN               NaN       NaN               NaN            NaN   \n",
       "\n",
       "     /other/product /other/event/sports_event /other/event /other/art  \\\n",
       "0               NaN                       NaN          NaN        NaN   \n",
       "1               NaN                       NaN          NaN        NaN   \n",
       "2               NaN                       NaN          NaN        NaN   \n",
       "3               NaN                       NaN          NaN        NaN   \n",
       "4               NaN                       NaN          NaN        NaN   \n",
       "...             ...                       ...          ...        ...   \n",
       "8958            NaN                       NaN          NaN        NaN   \n",
       "8959            NaN                       NaN          NaN        NaN   \n",
       "8960            NaN                       NaN          NaN        NaN   \n",
       "8961            NaN                       NaN          NaN        NaN   \n",
       "8962            NaN                       NaN          NaN        NaN   \n",
       "\n",
       "     /other/art/broadcast  ... /organization/stock_exchange  \\\n",
       "0                     NaN  ...                          NaN   \n",
       "1                     NaN  ...                          NaN   \n",
       "2                     NaN  ...                          NaN   \n",
       "3                     NaN  ...                          NaN   \n",
       "4                     NaN  ...                          NaN   \n",
       "...                   ...  ...                          ...   \n",
       "8958                  NaN  ...                          NaN   \n",
       "8959                  NaN  ...                          NaN   \n",
       "8960                  NaN  ...                          NaN   \n",
       "8961                  NaN  ...                          NaN   \n",
       "8962                  NaN  ...                          NaN   \n",
       "\n",
       "     /location/transit/bridge /organization/company/broadcast  \\\n",
       "0                         NaN                             NaN   \n",
       "1                         NaN                             NaN   \n",
       "2                         NaN                             NaN   \n",
       "3                         NaN                             NaN   \n",
       "4                         NaN                             NaN   \n",
       "...                       ...                             ...   \n",
       "8958                      NaN                             NaN   \n",
       "8959                      NaN                             NaN   \n",
       "8960                      NaN                             NaN   \n",
       "8961                      NaN                             NaN   \n",
       "8962                      NaN                             NaN   \n",
       "\n",
       "     /organization/transit /location/structure/theater  \\\n",
       "0                      NaN                         NaN   \n",
       "1                      NaN                         NaN   \n",
       "2                      NaN                         NaN   \n",
       "3                      NaN                         NaN   \n",
       "4                      NaN                         NaN   \n",
       "...                    ...                         ...   \n",
       "8958                   NaN                         NaN   \n",
       "8959                   NaN                         NaN   \n",
       "8960                   NaN                         NaN   \n",
       "8961                   NaN                         NaN   \n",
       "8962                   NaN                         NaN   \n",
       "\n",
       "     /location/geography/body_of_water /location/geograpy/island  \\\n",
       "0                                  NaN                       NaN   \n",
       "1                                  NaN                       NaN   \n",
       "2                                  NaN                       NaN   \n",
       "3                                  NaN                       NaN   \n",
       "4                                  NaN                       NaN   \n",
       "...                                ...                       ...   \n",
       "8958                               NaN                       NaN   \n",
       "8959                               NaN                       NaN   \n",
       "8960                               NaN                       NaN   \n",
       "8961                               NaN                       NaN   \n",
       "8962                               NaN                       NaN   \n",
       "\n",
       "     /location/geograpy /other/legal /other/product/mobile_phone  \n",
       "0                   NaN          NaN                         NaN  \n",
       "1                   NaN          NaN                         NaN  \n",
       "2                   NaN          NaN                         NaN  \n",
       "3                   NaN          NaN                         NaN  \n",
       "4                   NaN          NaN                         NaN  \n",
       "...                 ...          ...                         ...  \n",
       "8958                NaN          NaN                         NaN  \n",
       "8959                NaN          NaN                         NaN  \n",
       "8960                NaN          NaN                         NaN  \n",
       "8961                NaN          NaN                         NaN  \n",
       "8962                NaN          NaN                         NaN  \n",
       "\n",
       "[8963 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Find out which predictions still need to be made\n",
    "todo = predictions_df.isna().any(axis=1)\n",
    "print(f'Progress: {(~todo).mean() * 100:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8963/8963 [05:19<00:00, 28.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for the remaining rows\n",
    "with torch.no_grad():  # Disable gradient calculation for speed\n",
    "    # Keep track of how many predictions have been made since the last save\n",
    "    new_predictions_counter = 0\n",
    "\n",
    "    # Iterate over all rows in the dev data\n",
    "    for row in tqdm(data.loc[todo, :].itertuples(), total=todo.sum()):\n",
    "\n",
    "        # Predict the type of the mention and store the prediction\n",
    "        entailment_probabilities = predict_probabilities(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            row.sentence,\n",
    "            row.mention_span,\n",
    "            all_types['type'],\n",
    "            hypothesis_only=HYPOTHESIS_ONLY)[0, :, -1]  # -1 is the entailment class\n",
    "\n",
    "        # Store the prediction\n",
    "        predictions_df.loc[row.Index, :] = entailment_probabilities\n",
    "\n",
    "        # Save the predictions to file every SAVE_EVERY predictions\n",
    "        new_predictions_counter += 1\n",
    "        if new_predictions_counter >= SAVE_EVERY:\n",
    "            \n",
    "            # Save the predictions to file\n",
    "            predictions_df.to_csv(SAVE_PREDICTIONS_TO)\n",
    "            new_predictions_counter = 0\n",
    "\n",
    "# Save the remaining predictions to file\n",
    "predictions_df.to_csv(SAVE_PREDICTIONS_TO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
