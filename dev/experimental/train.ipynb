{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlinec import get_positive_data, get_all_types, get_granularity, construct_hypothesis, get_type, combine_premise_hypothesis, get_models_dir, get_negative_data, combine_positive_negative_data\n",
    "from nlinec.predict import predict_type\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRANULARITY = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading augmented_train.json: 793487it [00:17, 44216.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading negative data from /home/psaegert/Projects/nli-nec/src/nlinec/../../data/derived/negative_data/augmented_train.json_42.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading g_dev.json: 2202it [00:00, 178453.43it/s]\n"
     ]
    }
   ],
   "source": [
    "positive_data = get_positive_data(\"augmented_train.json\", explode=True)\n",
    "negative_data = get_negative_data(\"augmented_train.json\", random_state=42)\n",
    "dev_data = get_positive_data(\"g_dev.json\", explode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combine_positive_negative_data(positive_data, negative_data, frac=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_type</th>\n",
       "      <th>mention_span</th>\n",
       "      <th>sentence</th>\n",
       "      <th>granularity</th>\n",
       "      <th>label</th>\n",
       "      <th>type_2</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/location/country</td>\n",
       "      <td>We</td>\n",
       "      <td>We did not do anything at that time.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "      <td>We is a country.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/organization/company</td>\n",
       "      <td>antibody</td>\n",
       "      <td>`` We don't know the effect of our antibody on...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>company</td>\n",
       "      <td>antibody is a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/other/product</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>The Visigoths of Spain were defeated when the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>product</td>\n",
       "      <td>Lisbon is a product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/other/product</td>\n",
       "      <td>non food crops or inedible waste products</td>\n",
       "      <td>Cellulosic ethanol production uses non food cr...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>product</td>\n",
       "      <td>non food crops or inedible waste products is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/location/geography/body_of_water</td>\n",
       "      <td>traditional games</td>\n",
       "      <td>In caffeehouses around you could see people sm...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>geography</td>\n",
       "      <td>traditional games is a geography.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864998</th>\n",
       "      <td>/person/artist</td>\n",
       "      <td>transfer</td>\n",
       "      <td>It marked the first peaceful transfer of power...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>transfer is a artist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864999</th>\n",
       "      <td>/other/internet</td>\n",
       "      <td>American</td>\n",
       "      <td>Right now, the American populace is spending a...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>internet</td>\n",
       "      <td>American is a internet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865001</th>\n",
       "      <td>/other/event/holiday</td>\n",
       "      <td>American</td>\n",
       "      <td>Right now, the American populace is spending a...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>event</td>\n",
       "      <td>American is a event.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865002</th>\n",
       "      <td>/location/structure</td>\n",
       "      <td>American</td>\n",
       "      <td>Right now, the American populace is spending a...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>structure</td>\n",
       "      <td>American is a structure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865006</th>\n",
       "      <td>/other/health</td>\n",
       "      <td>Japanese martial arts classes such as Aikido ,...</td>\n",
       "      <td>Sensei is often used to address the teacher in...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>health</td>\n",
       "      <td>Japanese martial arts classes such as Aikido ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813973 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 full_type  \\\n",
       "2                        /location/country   \n",
       "5                    /organization/company   \n",
       "6                           /other/product   \n",
       "8                           /other/product   \n",
       "10       /location/geography/body_of_water   \n",
       "...                                    ...   \n",
       "1864998                     /person/artist   \n",
       "1864999                    /other/internet   \n",
       "1865001               /other/event/holiday   \n",
       "1865002                /location/structure   \n",
       "1865006                      /other/health   \n",
       "\n",
       "                                              mention_span  \\\n",
       "2                                                       We   \n",
       "5                                                 antibody   \n",
       "6                                                   Lisbon   \n",
       "8                non food crops or inedible waste products   \n",
       "10                                       traditional games   \n",
       "...                                                    ...   \n",
       "1864998                                           transfer   \n",
       "1864999                                           American   \n",
       "1865001                                           American   \n",
       "1865002                                           American   \n",
       "1865006  Japanese martial arts classes such as Aikido ,...   \n",
       "\n",
       "                                                  sentence  granularity  \\\n",
       "2                     We did not do anything at that time.            2   \n",
       "5        `` We don't know the effect of our antibody on...            2   \n",
       "6        The Visigoths of Spain were defeated when the ...            2   \n",
       "8        Cellulosic ethanol production uses non food cr...            2   \n",
       "10       In caffeehouses around you could see people sm...            3   \n",
       "...                                                    ...          ...   \n",
       "1864998  It marked the first peaceful transfer of power...            2   \n",
       "1864999  Right now, the American populace is spending a...            2   \n",
       "1865001  Right now, the American populace is spending a...            3   \n",
       "1865002  Right now, the American populace is spending a...            2   \n",
       "1865006  Sensei is often used to address the teacher in...            2   \n",
       "\n",
       "         label     type_2                                         hypothesis  \n",
       "2            2    country                                   We is a country.  \n",
       "5            1    company                             antibody is a company.  \n",
       "6            1    product                               Lisbon is a product.  \n",
       "8            2    product  non food crops or inedible waste products is a...  \n",
       "10           1  geography                  traditional games is a geography.  \n",
       "...        ...        ...                                                ...  \n",
       "1864998      1     artist                              transfer is a artist.  \n",
       "1864999      1   internet                            American is a internet.  \n",
       "1865001      1      event                               American is a event.  \n",
       "1865002      2  structure                           American is a structure.  \n",
       "1865006      1     health  Japanese martial arts classes such as Aikido ,...  \n",
       "\n",
       "[813973 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the basic type\n",
    "data[f'type_{GRANULARITY}'] = data['full_type'].apply(lambda x: get_type(x, GRANULARITY))\n",
    "dev_data[f'type_{GRANULARITY}'] = dev_data['full_type'].apply(lambda x: get_type(x, GRANULARITY))\n",
    "\n",
    "# Remove the rows with type None or \"other\"\n",
    "data = data[data[f'type_{GRANULARITY}'].notna()]\n",
    "dev_data = dev_data[dev_data[f'type_{GRANULARITY}'].notna()]\n",
    "# data = data[data[f'type_{GRANULARITY}'] != 'other']\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates(subset=['mention_span', 'sentence', f'type_{GRANULARITY}'])\n",
    "dev_data = dev_data.drop_duplicates(subset=['mention_span', 'sentence', f'type_{GRANULARITY}'])\n",
    "\n",
    "# Construct the hypothesis\n",
    "data[\"hypothesis\"] = data.apply(lambda row: construct_hypothesis(row[\"mention_span\"], row[f'type_{GRANULARITY}']), axis=1)\n",
    "dev_data[\"hypothesis\"] = dev_data.apply(lambda row: construct_hypothesis(row[\"mention_span\"], row[f'type_{GRANULARITY}']), axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_types = []\n",
    "for i in [1, 2, 3]:\n",
    "    all_types = get_all_types(granularity=i)\n",
    "    all_types['granularity'] = all_types['full_type'].apply(lambda x: get_granularity(x))\n",
    "    gran_types.append(all_types[all_types['granularity'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting types: 100%|██████████| 866/866 [00:50<00:00, 17.26it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dev_predictions = predict_type(model, tokenizer, list(dev_data['sentence']), list(dev_data['mention_span']), list(gran_types[1]['type']), return_str=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention_span</th>\n",
       "      <th>full_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>granularity</th>\n",
       "      <th>label</th>\n",
       "      <th>type_2</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prediction_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan</td>\n",
       "      <td>/location/country</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "      <td>Japan is a country.</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the Bank of Japan</td>\n",
       "      <td>/location/structure</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>structure</td>\n",
       "      <td>the Bank of Japan is a structure.</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the Bank of Japan</td>\n",
       "      <td>/organization/government</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>the Bank of Japan is a government.</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the Bank</td>\n",
       "      <td>/location/structure</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>structure</td>\n",
       "      <td>the Bank is a structure.</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Japan 's</td>\n",
       "      <td>/location/country</td>\n",
       "      <td>Japan 's wholesale prices in September rose 3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "      <td>Japan 's is a country.</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Europe</td>\n",
       "      <td>/location/geography</td>\n",
       "      <td>There were no major Eurobond or foreign bond o...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>geography</td>\n",
       "      <td>Europe is a geography.</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>$ 150 million</td>\n",
       "      <td>/other/currency</td>\n",
       "      <td>$ 150 million of 9 % debentures due Oct. 15, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>currency</td>\n",
       "      <td>$ 150 million is a currency.</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>the Treasury 's</td>\n",
       "      <td>/organization/government</td>\n",
       "      <td>The non-callable issue, which can be put back ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>the Treasury 's is a government.</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>the Treasury 's</td>\n",
       "      <td>/organization/government</td>\n",
       "      <td>The issue, which is puttable back to the compa...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>the Treasury 's is a government.</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>$ 200 million</td>\n",
       "      <td>/other/currency</td>\n",
       "      <td>$ 200 million of stripped mortgage securities...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>currency</td>\n",
       "      <td>$ 200 million is a currency.</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mention_span                 full_type  \\\n",
       "3                 Japan         /location/country   \n",
       "5     the Bank of Japan       /location/structure   \n",
       "7     the Bank of Japan  /organization/government   \n",
       "15             the Bank       /location/structure   \n",
       "18             Japan 's         /location/country   \n",
       "...                 ...                       ...   \n",
       "3264             Europe       /location/geography   \n",
       "3267      $ 150 million           /other/currency   \n",
       "3275    the Treasury 's  /organization/government   \n",
       "3278    the Treasury 's  /organization/government   \n",
       "3281      $ 200 million           /other/currency   \n",
       "\n",
       "                                               sentence  granularity  label  \\\n",
       "3     Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "5     Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "7     Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "15    Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "18     Japan 's wholesale prices in September rose 3...            2      2   \n",
       "...                                                 ...          ...    ...   \n",
       "3264  There were no major Eurobond or foreign bond o...            2      2   \n",
       "3267   $ 150 million of 9 % debentures due Oct. 15, ...            2      2   \n",
       "3275  The non-callable issue, which can be put back ...            2      2   \n",
       "3278  The issue, which is puttable back to the compa...            2      2   \n",
       "3281   $ 200 million of stripped mortgage securities...            2      2   \n",
       "\n",
       "          type_2                          hypothesis prediction_before  \n",
       "3        country                 Japan is a country.           country  \n",
       "5      structure   the Bank of Japan is a structure.             title  \n",
       "7     government  the Bank of Japan is a government.             title  \n",
       "15     structure            the Bank is a structure.             event  \n",
       "18       country              Japan 's is a country.           product  \n",
       "...          ...                                 ...               ...  \n",
       "3264   geography              Europe is a geography.             title  \n",
       "3267    currency        $ 150 million is a currency.           product  \n",
       "3275  government    the Treasury 's is a government.           product  \n",
       "3278  government    the Treasury 's is a government.           product  \n",
       "3281    currency        $ 200 million is a currency.           product  \n",
       "\n",
       "[866 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data['prediction_before'] = dev_predictions\n",
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample accuracy: 0.32217090069284066\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample accuracy: {(dev_data[f'type_{GRANULARITY}'] == dev_data['prediction_before']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# Make the data usable by the model\n",
    "# The input is of the form: sentence</s><s>hypothesis\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "train_dataset = Dataset.from_pandas(data.loc[:, [\"sentence\", \"hypothesis\", \"label\"]])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # input_text = examples[\"sentence\"] + \"</s><s>\" + examples[\"hypothesis\"]\n",
    "    input_text = [combine_premise_hypothesis(sentence, hypothesis) for sentence, hypothesis in zip(examples[\"sentence\"], examples[\"hypothesis\"])]\n",
    "    return tokenizer(input_text, max_length=model.config.max_position_embeddings, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(get_models_dir(), f'nlinec-positive-{GRANULARITY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    # per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=3000,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_steps=3000,\n",
    "    # load_best_model_at_end=True,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    evaluation_strategy='no',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    # eval_dataset=tokenized_val_dataset,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: sentence, hypothesis. If sentence, hypothesis are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/psaegert/miniconda3/envs/fsem/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 500317\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 15635\n",
      "  Number of trainable parameters = 355362819\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='15635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/15635 00:01 < 6:05:22, 0.71 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/fsem/lib/python3.10/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1544\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1545\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1546\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1547\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1548\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/fsem/lib/python3.10/site-packages/transformers/trainer.py:1791\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1794\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1795\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1796\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1797\u001b[0m ):\n\u001b[1;32m   1798\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1799\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/fsem/lib/python3.10/site-packages/transformers/trainer.py:2557\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2555\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39mbackward(loss)\n\u001b[1;32m   2556\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2557\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m   2559\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/fsem/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/fsem/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/psaegert/Projects/nli-nec/src/nlinec/../../models/nlinec-positive-2\n",
      "Configuration saved in /home/psaegert/Projects/nli-nec/src/nlinec/../../models/nlinec-positive-2/config.json\n",
      "Model weights saved in /home/psaegert/Projects/nli-nec/src/nlinec/../../models/nlinec-positive-2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting types: 100%|██████████| 866/866 [00:52<00:00, 16.52it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dev_predictions = predict_type(model, tokenizer, list(dev_data['sentence']), list(dev_data['mention_span']), list(gran_types[1]['type']), return_str=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention_span</th>\n",
       "      <th>full_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>granularity</th>\n",
       "      <th>label</th>\n",
       "      <th>type_2</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prediction_before</th>\n",
       "      <th>prediction_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan</td>\n",
       "      <td>/location/country</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "      <td>Japan is a country.</td>\n",
       "      <td>country</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the Bank of Japan</td>\n",
       "      <td>/location/structure</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>structure</td>\n",
       "      <td>the Bank of Japan is a structure.</td>\n",
       "      <td>title</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the Bank of Japan</td>\n",
       "      <td>/organization/government</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>the Bank of Japan is a government.</td>\n",
       "      <td>title</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the Bank</td>\n",
       "      <td>/location/structure</td>\n",
       "      <td>Japan's wholesale prices in September rose 3.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>structure</td>\n",
       "      <td>the Bank is a structure.</td>\n",
       "      <td>event</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Japan 's</td>\n",
       "      <td>/location/country</td>\n",
       "      <td>Japan 's wholesale prices in September rose 3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "      <td>Japan 's is a country.</td>\n",
       "      <td>product</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Europe</td>\n",
       "      <td>/location/geography</td>\n",
       "      <td>There were no major Eurobond or foreign bond o...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>geography</td>\n",
       "      <td>Europe is a geography.</td>\n",
       "      <td>title</td>\n",
       "      <td>sports_team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>$ 150 million</td>\n",
       "      <td>/other/currency</td>\n",
       "      <td>$ 150 million of 9 % debentures due Oct. 15, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>currency</td>\n",
       "      <td>$ 150 million is a currency.</td>\n",
       "      <td>product</td>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>the Treasury 's</td>\n",
       "      <td>/organization/government</td>\n",
       "      <td>The non-callable issue, which can be put back ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>the Treasury 's is a government.</td>\n",
       "      <td>product</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>the Treasury 's</td>\n",
       "      <td>/organization/government</td>\n",
       "      <td>The issue, which is puttable back to the compa...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>the Treasury 's is a government.</td>\n",
       "      <td>product</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>$ 200 million</td>\n",
       "      <td>/other/currency</td>\n",
       "      <td>$ 200 million of stripped mortgage securities...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>currency</td>\n",
       "      <td>$ 200 million is a currency.</td>\n",
       "      <td>product</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mention_span                 full_type  \\\n",
       "3                 Japan         /location/country   \n",
       "5     the Bank of Japan       /location/structure   \n",
       "7     the Bank of Japan  /organization/government   \n",
       "15             the Bank       /location/structure   \n",
       "18             Japan 's         /location/country   \n",
       "...                 ...                       ...   \n",
       "3264             Europe       /location/geography   \n",
       "3267      $ 150 million           /other/currency   \n",
       "3275    the Treasury 's  /organization/government   \n",
       "3278    the Treasury 's  /organization/government   \n",
       "3281      $ 200 million           /other/currency   \n",
       "\n",
       "                                               sentence  granularity  label  \\\n",
       "3     Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "5     Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "7     Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "15    Japan's wholesale prices in September rose 3.3...            2      2   \n",
       "18     Japan 's wholesale prices in September rose 3...            2      2   \n",
       "...                                                 ...          ...    ...   \n",
       "3264  There were no major Eurobond or foreign bond o...            2      2   \n",
       "3267   $ 150 million of 9 % debentures due Oct. 15, ...            2      2   \n",
       "3275  The non-callable issue, which can be put back ...            2      2   \n",
       "3278  The issue, which is puttable back to the compa...            2      2   \n",
       "3281   $ 200 million of stripped mortgage securities...            2      2   \n",
       "\n",
       "          type_2                          hypothesis prediction_before  \\\n",
       "3        country                 Japan is a country.           country   \n",
       "5      structure   the Bank of Japan is a structure.             title   \n",
       "7     government  the Bank of Japan is a government.             title   \n",
       "15     structure            the Bank is a structure.             event   \n",
       "18       country              Japan 's is a country.           product   \n",
       "...          ...                                 ...               ...   \n",
       "3264   geography              Europe is a geography.             title   \n",
       "3267    currency        $ 150 million is a currency.           product   \n",
       "3275  government    the Treasury 's is a government.           product   \n",
       "3278  government    the Treasury 's is a government.           product   \n",
       "3281    currency        $ 200 million is a currency.           product   \n",
       "\n",
       "     prediction_after  \n",
       "3              health  \n",
       "5             transit  \n",
       "7             transit  \n",
       "15              legal  \n",
       "18          education  \n",
       "...               ...  \n",
       "3264      sports_team  \n",
       "3267         currency  \n",
       "3275            coach  \n",
       "3278          product  \n",
       "3281          product  \n",
       "\n",
       "[866 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data['prediction_after'] = dev_predictions\n",
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample accuracy after training: 0.028868360277136258\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample accuracy after training: {(dev_data[f'type_{GRANULARITY}'] == dev_data['prediction_after']).mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
