{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlinec.data.load import get_positive_data\n",
    "from nlinec.data.preprocessing import construct_hypothesis, get_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "793487it [00:10, 77172.11it/s] \n"
     ]
    }
   ],
   "source": [
    "data = get_positive_data(\"augmented_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mention_span</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fixed_granularity_type</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/location/country</td>\n",
       "      <td>We</td>\n",
       "      <td>We did not do anything at that time.</td>\n",
       "      <td>country</td>\n",
       "      <td>We is a country.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/other/scientific</td>\n",
       "      <td>antibody</td>\n",
       "      <td>`` We don't know the effect of our antibody on...</td>\n",
       "      <td>scientific</td>\n",
       "      <td>antibody is a scientific.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>The Visigoths of Spain were defeated when the ...</td>\n",
       "      <td>city</td>\n",
       "      <td>Lisbon is a city.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/other/product</td>\n",
       "      <td>non food crops or inedible waste products</td>\n",
       "      <td>Cellulosic ethanol production uses non food cr...</td>\n",
       "      <td>product</td>\n",
       "      <td>non food crops or inedible waste products is a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/other/event/sports_event</td>\n",
       "      <td>traditional games</td>\n",
       "      <td>In caffeehouses around you could see people sm...</td>\n",
       "      <td>event</td>\n",
       "      <td>traditional games is a event.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864991</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>Baghdad</td>\n",
       "      <td>Journalists held a candle light vigil in Baghd...</td>\n",
       "      <td>city</td>\n",
       "      <td>Baghdad is a city.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864993</th>\n",
       "      <td>/other/event/sports_event</td>\n",
       "      <td>The game</td>\n",
       "      <td>The game features 25 songs by Van Halen, 3 gu...</td>\n",
       "      <td>event</td>\n",
       "      <td>The game is a event.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864997</th>\n",
       "      <td>/other/health/treatment</td>\n",
       "      <td>transfer</td>\n",
       "      <td>It marked the first peaceful transfer of power...</td>\n",
       "      <td>health</td>\n",
       "      <td>transfer is a health.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864999</th>\n",
       "      <td>/location/country</td>\n",
       "      <td>American</td>\n",
       "      <td>Right now, the American populace is spending a...</td>\n",
       "      <td>country</td>\n",
       "      <td>American is a country.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865001</th>\n",
       "      <td>/location/structure/government</td>\n",
       "      <td>American</td>\n",
       "      <td>Right now, the American populace is spending a...</td>\n",
       "      <td>structure</td>\n",
       "      <td>American is a structure.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500317 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   type  \\\n",
       "2                     /location/country   \n",
       "5                     /other/scientific   \n",
       "6                        /location/city   \n",
       "8                        /other/product   \n",
       "10            /other/event/sports_event   \n",
       "...                                 ...   \n",
       "1864991                  /location/city   \n",
       "1864993       /other/event/sports_event   \n",
       "1864997         /other/health/treatment   \n",
       "1864999               /location/country   \n",
       "1865001  /location/structure/government   \n",
       "\n",
       "                                      mention_span  \\\n",
       "2                                               We   \n",
       "5                                         antibody   \n",
       "6                                           Lisbon   \n",
       "8        non food crops or inedible waste products   \n",
       "10                               traditional games   \n",
       "...                                            ...   \n",
       "1864991                                    Baghdad   \n",
       "1864993                                   The game   \n",
       "1864997                                   transfer   \n",
       "1864999                                   American   \n",
       "1865001                                   American   \n",
       "\n",
       "                                                  sentence  \\\n",
       "2                     We did not do anything at that time.   \n",
       "5        `` We don't know the effect of our antibody on...   \n",
       "6        The Visigoths of Spain were defeated when the ...   \n",
       "8        Cellulosic ethanol production uses non food cr...   \n",
       "10       In caffeehouses around you could see people sm...   \n",
       "...                                                    ...   \n",
       "1864991  Journalists held a candle light vigil in Baghd...   \n",
       "1864993   The game features 25 songs by Van Halen, 3 gu...   \n",
       "1864997  It marked the first peaceful transfer of power...   \n",
       "1864999  Right now, the American populace is spending a...   \n",
       "1865001  Right now, the American populace is spending a...   \n",
       "\n",
       "        fixed_granularity_type  \\\n",
       "2                      country   \n",
       "5                   scientific   \n",
       "6                         city   \n",
       "8                      product   \n",
       "10                       event   \n",
       "...                        ...   \n",
       "1864991                   city   \n",
       "1864993                  event   \n",
       "1864997                 health   \n",
       "1864999                country   \n",
       "1865001              structure   \n",
       "\n",
       "                                                hypothesis  label  \n",
       "2                                         We is a country.      2  \n",
       "5                                antibody is a scientific.      2  \n",
       "6                                        Lisbon is a city.      2  \n",
       "8        non food crops or inedible waste products is a...      2  \n",
       "10                           traditional games is a event.      2  \n",
       "...                                                    ...    ...  \n",
       "1864991                                 Baghdad is a city.      2  \n",
       "1864993                               The game is a event.      2  \n",
       "1864997                              transfer is a health.      2  \n",
       "1864999                             American is a country.      2  \n",
       "1865001                           American is a structure.      2  \n",
       "\n",
       "[500317 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the basic type\n",
    "data['fixed_granularity_type'] = data['type'].apply(lambda x: get_type(x, 2))\n",
    "\n",
    "# Remove the rows with type None or \"other\"\n",
    "data = data[data['fixed_granularity_type'].notna()]\n",
    "data = data[data['fixed_granularity_type'] != 'other']\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates(subset=['mention_span', 'sentence', 'fixed_granularity_type'])\n",
    "\n",
    "# Construct the hypothesis\n",
    "data[\"hypothesis\"] = data.apply(lambda row: construct_hypothesis(row[\"mention_span\"], row[\"fixed_granularity_type\"]), axis=1)\n",
    "\n",
    "# Mark all rows as entailed\n",
    "data[\"label\"] = 2\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['country', 'scientific', 'city', 'product', 'event', 'art',\n",
       "       'artist', 'political_figure', 'military', 'company', 'structure',\n",
       "       'title', 'language', 'sports_team', 'music', 'coach',\n",
       "       'living_thing', 'body_part', 'park', 'currency', 'geography',\n",
       "       'health', 'political_party', 'government', 'supernatural',\n",
       "       'transit', 'education', 'food', 'athlete', 'award',\n",
       "       'religious_leader', 'religion', 'legal', 'internet', 'celestial',\n",
       "       'heritage', 'doctor', 'sports_and_leisure', 'sports_league',\n",
       "       'stock_exchange', 'geograpy'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_types = data['fixed_granularity_type'].unique()\n",
    "possible_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psaegert/miniconda3/envs/fsem/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlinec.predict import predict_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mention_span</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fixed_granularity_type</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/location/structure/government</td>\n",
       "      <td>US</td>\n",
       "      <td>Of course, the US military is going to jump at...</td>\n",
       "      <td>structure</td>\n",
       "      <td>US is a structure.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/location/structure</td>\n",
       "      <td>uncovered</td>\n",
       "      <td>Ms. Rose, who teaches literature at Wesleyan U...</td>\n",
       "      <td>structure</td>\n",
       "      <td>uncovered is a structure.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/other/product</td>\n",
       "      <td>investment bankers</td>\n",
       "      <td>The turmoil on Wall Street may benefit some re...</td>\n",
       "      <td>product</td>\n",
       "      <td>investment bankers is a product.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>In 1699 Liverpool was made a parish by Act of ...</td>\n",
       "      <td>city</td>\n",
       "      <td>Liverpool is a city.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/organization/company</td>\n",
       "      <td>Peugeot</td>\n",
       "      <td>One of them splashed gasoline on the Peugeot .</td>\n",
       "      <td>company</td>\n",
       "      <td>Peugeot is a company.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>/person/title</td>\n",
       "      <td>So</td>\n",
       "      <td>`` So I tell you, don't worry about the things...</td>\n",
       "      <td>title</td>\n",
       "      <td>So is a title.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>London</td>\n",
       "      <td>One edition was published in London with Charl...</td>\n",
       "      <td>city</td>\n",
       "      <td>London is a city.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>/person/artist/author</td>\n",
       "      <td>US journalist Helen Thomas</td>\n",
       "      <td>Noted US journalist Helen Thomas told a Hebrew...</td>\n",
       "      <td>artist</td>\n",
       "      <td>US journalist Helen Thomas is a artist.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>every city in the United States</td>\n",
       "      <td>Neon signage was adopted with increasing frequ...</td>\n",
       "      <td>city</td>\n",
       "      <td>every city in the United States is a city.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>/location/country</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Once Egypt supplied Israel with the full detai...</td>\n",
       "      <td>country</td>\n",
       "      <td>Israel is a country.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              type                     mention_span  \\\n",
       "0   /location/structure/government                               US   \n",
       "1              /location/structure                        uncovered   \n",
       "2                   /other/product               investment bankers   \n",
       "3                   /location/city                        Liverpool   \n",
       "4            /organization/company                          Peugeot   \n",
       "..                             ...                              ...   \n",
       "95                   /person/title                               So   \n",
       "96                  /location/city                           London   \n",
       "97           /person/artist/author       US journalist Helen Thomas   \n",
       "98                  /location/city  every city in the United States   \n",
       "99               /location/country                           Israel   \n",
       "\n",
       "                                             sentence fixed_granularity_type  \\\n",
       "0   Of course, the US military is going to jump at...              structure   \n",
       "1   Ms. Rose, who teaches literature at Wesleyan U...              structure   \n",
       "2   The turmoil on Wall Street may benefit some re...                product   \n",
       "3   In 1699 Liverpool was made a parish by Act of ...                   city   \n",
       "4      One of them splashed gasoline on the Peugeot .                company   \n",
       "..                                                ...                    ...   \n",
       "95  `` So I tell you, don't worry about the things...                  title   \n",
       "96  One edition was published in London with Charl...                   city   \n",
       "97  Noted US journalist Helen Thomas told a Hebrew...                 artist   \n",
       "98  Neon signage was adopted with increasing frequ...                   city   \n",
       "99  Once Egypt supplied Israel with the full detai...                country   \n",
       "\n",
       "                                    hypothesis  label  \n",
       "0                           US is a structure.      2  \n",
       "1                    uncovered is a structure.      2  \n",
       "2             investment bankers is a product.      2  \n",
       "3                         Liverpool is a city.      2  \n",
       "4                        Peugeot is a company.      2  \n",
       "..                                         ...    ...  \n",
       "95                              So is a title.      2  \n",
       "96                           London is a city.      2  \n",
       "97     US journalist Helen Thomas is a artist.      2  \n",
       "98  every city in the United States is a city.      2  \n",
       "99                        Israel is a country.      2  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sample = val_data.sample(100).reset_index(drop=True)\n",
    "val_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting types: 100%|██████████| 100/100 [04:02<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "val_predictions = predict_type(model, tokenizer, val_sample['sentence'], val_sample['mention_span'], possible_types, return_str=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mention_span</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fixed_granularity_type</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/location/structure/government</td>\n",
       "      <td>US</td>\n",
       "      <td>Of course, the US military is going to jump at...</td>\n",
       "      <td>structure</td>\n",
       "      <td>US is a structure.</td>\n",
       "      <td>2</td>\n",
       "      <td>military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/location/structure</td>\n",
       "      <td>uncovered</td>\n",
       "      <td>Ms. Rose, who teaches literature at Wesleyan U...</td>\n",
       "      <td>structure</td>\n",
       "      <td>uncovered is a structure.</td>\n",
       "      <td>2</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/other/product</td>\n",
       "      <td>investment bankers</td>\n",
       "      <td>The turmoil on Wall Street may benefit some re...</td>\n",
       "      <td>product</td>\n",
       "      <td>investment bankers is a product.</td>\n",
       "      <td>2</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>In 1699 Liverpool was made a parish by Act of ...</td>\n",
       "      <td>city</td>\n",
       "      <td>Liverpool is a city.</td>\n",
       "      <td>2</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/organization/company</td>\n",
       "      <td>Peugeot</td>\n",
       "      <td>One of them splashed gasoline on the Peugeot .</td>\n",
       "      <td>company</td>\n",
       "      <td>Peugeot is a company.</td>\n",
       "      <td>2</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>/person/title</td>\n",
       "      <td>So</td>\n",
       "      <td>`` So I tell you, don't worry about the things...</td>\n",
       "      <td>title</td>\n",
       "      <td>So is a title.</td>\n",
       "      <td>2</td>\n",
       "      <td>living_thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>London</td>\n",
       "      <td>One edition was published in London with Charl...</td>\n",
       "      <td>city</td>\n",
       "      <td>London is a city.</td>\n",
       "      <td>2</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>/person/artist/author</td>\n",
       "      <td>US journalist Helen Thomas</td>\n",
       "      <td>Noted US journalist Helen Thomas told a Hebrew...</td>\n",
       "      <td>artist</td>\n",
       "      <td>US journalist Helen Thomas is a artist.</td>\n",
       "      <td>2</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>/location/city</td>\n",
       "      <td>every city in the United States</td>\n",
       "      <td>Neon signage was adopted with increasing frequ...</td>\n",
       "      <td>city</td>\n",
       "      <td>every city in the United States is a city.</td>\n",
       "      <td>2</td>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>/location/country</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Once Egypt supplied Israel with the full detai...</td>\n",
       "      <td>country</td>\n",
       "      <td>Israel is a country.</td>\n",
       "      <td>2</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              type                     mention_span  \\\n",
       "0   /location/structure/government                               US   \n",
       "1              /location/structure                        uncovered   \n",
       "2                   /other/product               investment bankers   \n",
       "3                   /location/city                        Liverpool   \n",
       "4            /organization/company                          Peugeot   \n",
       "..                             ...                              ...   \n",
       "95                   /person/title                               So   \n",
       "96                  /location/city                           London   \n",
       "97           /person/artist/author       US journalist Helen Thomas   \n",
       "98                  /location/city  every city in the United States   \n",
       "99               /location/country                           Israel   \n",
       "\n",
       "                                             sentence fixed_granularity_type  \\\n",
       "0   Of course, the US military is going to jump at...              structure   \n",
       "1   Ms. Rose, who teaches literature at Wesleyan U...              structure   \n",
       "2   The turmoil on Wall Street may benefit some re...                product   \n",
       "3   In 1699 Liverpool was made a parish by Act of ...                   city   \n",
       "4      One of them splashed gasoline on the Peugeot .                company   \n",
       "..                                                ...                    ...   \n",
       "95  `` So I tell you, don't worry about the things...                  title   \n",
       "96  One edition was published in London with Charl...                   city   \n",
       "97  Noted US journalist Helen Thomas told a Hebrew...                 artist   \n",
       "98  Neon signage was adopted with increasing frequ...                   city   \n",
       "99  Once Egypt supplied Israel with the full detai...                country   \n",
       "\n",
       "                                    hypothesis  label    prediction  \n",
       "0                           US is a structure.      2      military  \n",
       "1                    uncovered is a structure.      2         title  \n",
       "2             investment bankers is a product.      2         title  \n",
       "3                         Liverpool is a city.      2         legal  \n",
       "4                        Peugeot is a company.      2       product  \n",
       "..                                         ...    ...           ...  \n",
       "95                              So is a title.      2  living_thing  \n",
       "96                           London is a city.      2         title  \n",
       "97     US journalist Helen Thomas is a artist.      2       product  \n",
       "98  every city in the United States is a city.      2          city  \n",
       "99                        Israel is a country.      2       country  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sample['prediction'] = val_predictions\n",
    "val_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample accuracy: 0.22\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample accuracy: {(val_sample['fixed_granularity_type'] == val_sample['prediction']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# Make the data usable by the model\n",
    "# The input is of the form: sentence</s><s>hypothesis\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data.reset_index(drop=True).loc[:, [\"sentence\", \"hypothesis\", \"label\"]])\n",
    "val_dataset = Dataset.from_pandas(val_data.reset_index(drop=True).loc[:, [\"sentence\", \"hypothesis\", \"label\"]])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    input_text = examples[\"sentence\"] + \"</s><s>\" + examples[\"hypothesis\"]\n",
    "    return tokenizer(input_text, max_length=model.config.max_position_embeddings, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: sentence, hypothesis. If sentence, hypothesis are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 264426\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 24789\n",
      "  Number of trainable parameters = 355362819\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='24789' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    2/24789 : < :, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='8264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   1/8264 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: sentence, hypothesis. If sentence, hypothesis are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66107\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66107\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
